{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMEMQueryBuilder\n",
    "\n",
    "The CMEM query builder generates a SPARQL query based on a given ontology and a natural language question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmem-cmempy in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (24.3.0)\n",
      "Requirement already satisfied: llama-index in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (0.12.11)\n",
      "Requirement already satisfied: python-dotenv in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from cmem-cmempy) (2024.12.14)\n",
      "Requirement already satisfied: pyparsing<4.0.0,>=3.1.1 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from cmem-cmempy) (3.2.1)\n",
      "Requirement already satisfied: rdflib<7.0.0,>=6.3.2 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from cmem-cmempy) (6.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from cmem-cmempy) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from cmem-cmempy) (1.0.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.4.2)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.11 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.12.11)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.6.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.3.13)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.4.2)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.4.3)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.59.8)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.11->llama-index) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (2024.12.0)\n",
      "Requirement already satisfied: httpx in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (2.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.11->llama-index) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.9)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pandas in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.19)\n",
      "Requirement already satisfied: click in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from rdflib<7.0.0,>=6.3.2->cmem-cmempy) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.31.0->cmem-cmempy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.31.0->cmem-cmempy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.31.0->cmem-cmempy) (2.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.11->llama-index) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.11->llama-index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.11->llama-index) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.11->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.11->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.11->llama-index) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.11->llama-index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: six in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from isodate<0.7.0,>=0.6.0->rdflib<7.0.0,>=6.3.2->cmem-cmempy) (1.17.0)\n",
      "Requirement already satisfied: anyio in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.11->llama-index) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.11->llama-index) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.11->llama-index) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.11->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.11->llama-index) (2.27.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.11->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.11->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.11->llama-index) (3.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/rene/Documents/git/github/eccenca/llama-index-cmem/.venv/lib/python3.13/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.11->llama-index) (24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cmem-cmempy llama-index python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load environment from `.env` file. \n",
    "Start by `cp .env-template .env` and edit the content of `.env` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%reload_ext dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "model = \"gpt-4o-mini\"\n",
    "llm = OpenAI(model=model)\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the query builder with an ontology graph and a context (integration) graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index_cmem.utils.cmem_query_builder import CMEMQueryBuilder\n",
    "\n",
    "ontology_graph = \"http://ld.company.org/prod-vocab/\"\n",
    "context_graph = \"http://ld.company.org/prod-inst/\"\n",
    "\n",
    "cmem_query_builder = CMEMQueryBuilder(\n",
    "    ontology_graph=ontology_graph, context_graph=context_graph, llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMEMQuery\n",
    "\n",
    "Now define your natural language question and let the query builder generate a SPARQL query.\n",
    "The query builder return a CMEMQuery object which holds llm predictions and sparql extracts. This allows to refine the SPARQL query as often as you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Prompt: _What is the product category where the most product managers are experts in?_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Prediction\n",
       "\n",
       "To answer the user question \"What is the product category where the most product managers are experts in?\" using the provided RDF ontology, we need to construct a SPARQL query that counts the number of product managers associated with each product category and then retrieves the category with the highest count.\n",
       "\n",
       "### SPARQL Query\n",
       "\n",
       "```sparql\n",
       "PREFIX pv: <http://ld.company.org/prod-vocab/>\n",
       "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
       "\n",
       "SELECT ?category (COUNT(?manager) AS ?managerCount)\n",
       "WHERE {\n",
       "    ?manager a pv:Manager .\n",
       "    ?manager pv:areaOfExpertise ?category .\n",
       "}\n",
       "GROUP BY ?category\n",
       "ORDER BY DESC(?managerCount)\n",
       "LIMIT 1\n",
       "```\n",
       "\n",
       "### Explanation of the Query\n",
       "\n",
       "1. **PREFIX Declarations**: We define the prefixes for the ontology we are using. `pv:` is the prefix for the product vocabulary.\n",
       "\n",
       "2. **SELECT Clause**: We want to select the product category (`?category`) and the count of product managers (`COUNT(?manager) AS ?managerCount`).\n",
       "\n",
       "3. **WHERE Clause**: \n",
       "   - We specify that `?manager` must be of type `pv:Manager`, which identifies them as product managers.\n",
       "   - We then link each manager to their area of expertise using the property `pv:areaOfExpertise`, which connects the manager to a product category (`?category`).\n",
       "\n",
       "4. **GROUP BY Clause**: We group the results by `?category` to aggregate the counts of managers for each category.\n",
       "\n",
       "5. **ORDER BY Clause**: We order the results in descending order based on the count of managers (`?managerCount`), so that the category with the most managers appears first.\n",
       "\n",
       "6. **LIMIT Clause**: We limit the results to just one entry, which will be the product category with the highest number of product managers.\n",
       "\n",
       "### Result\n",
       "This query will return the product category that has the most product managers as experts, along with the count of those managers.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### SPARQL\n",
       "\n",
       "```sparql\n",
       "PREFIX pv: <http://ld.company.org/prod-vocab/>\n",
       "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
       "\n",
       "SELECT ?category (COUNT(?manager) AS ?managerCount)\n",
       "WHERE {\n",
       "    ?manager a pv:Manager .\n",
       "    ?manager pv:areaOfExpertise ?category .\n",
       "}\n",
       "GROUP BY ?category\n",
       "ORDER BY DESC(?managerCount)\n",
       "LIMIT 1```\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "from llama_index_cmem.utils.cmem_query import CMEMQuery\n",
    "\n",
    "\n",
    "def generate(prompt: str) -> CMEMQuery:\n",
    "    \"\"\"Generate a CMEM query.\"\"\"\n",
    "    display(Markdown(f\"## Prompt: _{prompt}_\"))\n",
    "    cmem_query = cmem_query_builder.generate_sparql(question=prompt)\n",
    "    display(Markdown(f\"### Prediction\\n\\n{cmem_query.get_last_prediction()!s}\\n\\n\"))\n",
    "    display(Markdown(f\"### SPARQL\\n\\n```sparql\\n{cmem_query.get_last_sparql()!s}```\\n\\n\"))\n",
    "    return cmem_query\n",
    "\n",
    "\n",
    "question = \"What is the product category where the most product managers are experts in?\"\n",
    "generated_cmem_query = generate(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine query\n",
    "\n",
    "Sometimes the generated SPARQL don't work as expected. If so the query builder can be used to refine the generated SPARQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Prompt: _What is the product category where the most product managers are experts in?_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Prediction list\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To answer the user question \"What is the product category where the most product managers are experts in?\" using the provided RDF ontology, we need to construct a SPARQL query that counts the number of product managers associated with each product category and then retrieves the category with the highest count.\n",
       "\n",
       "### SPARQL Query\n",
       "\n",
       "```sparql\n",
       "PREFIX pv: <http://ld.company.org/prod-vocab/>\n",
       "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
       "\n",
       "SELECT ?category (COUNT(?manager) AS ?managerCount)\n",
       "WHERE {\n",
       "    ?manager a pv:Manager .\n",
       "    ?manager pv:areaOfExpertise ?category .\n",
       "}\n",
       "GROUP BY ?category\n",
       "ORDER BY DESC(?managerCount)\n",
       "LIMIT 1\n",
       "```\n",
       "\n",
       "### Explanation of the Query\n",
       "\n",
       "1. **PREFIX Declarations**: We define the prefixes for the ontology we are using. `pv:` is the prefix for the product vocabulary.\n",
       "\n",
       "2. **SELECT Clause**: We want to select the product category (`?category`) and the count of product managers (`COUNT(?manager) AS ?managerCount`).\n",
       "\n",
       "3. **WHERE Clause**: \n",
       "   - We specify that `?manager` must be of type `pv:Manager`, which identifies them as product managers.\n",
       "   - We then link each manager to their area of expertise using the property `pv:areaOfExpertise`, which connects the manager to a product category (`?category`).\n",
       "\n",
       "4. **GROUP BY Clause**: We group the results by `?category` to aggregate the counts of managers for each category.\n",
       "\n",
       "5. **ORDER BY Clause**: We order the results in descending order based on the count of managers (`?managerCount`), so that the category with the most managers appears first.\n",
       "\n",
       "6. **LIMIT Clause**: We limit the results to just one entry, which will be the product category with the highest number of product managers.\n",
       "\n",
       "### Result\n",
       "This query will return the product category that has the most product managers as experts, along with the count of those managers.\n",
       "-----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To refine the SPARQL query based on the user question \"What is the product category where the most product managers are experts in?\", we need to ensure that the query correctly counts the number of product managers associated with each product category and returns the category with the highest count. \n",
       "\n",
       "### Explanation of the Refinement:\n",
       "1. **Focus on Product Managers**: The query should specifically target instances of `pv:Manager` and their associated expertise in `pv:ProductCategory`.\n",
       "2. **Count Managers per Category**: We will count the number of managers for each category using `COUNT(?manager)`.\n",
       "3. **Ordering and Limiting Results**: The results should be ordered by the count of managers in descending order, and we will limit the results to return only the top category.\n",
       "\n",
       "### Refined SPARQL Query:\n",
       "```sparql\n",
       "PREFIX pv: <http://ld.company.org/prod-vocab/>\n",
       "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
       "\n",
       "SELECT ?category (COUNT(?manager) AS ?managerCount)\n",
       "WHERE {\n",
       "    ?manager a pv:Manager .\n",
       "    ?manager pv:areaOfExpertise ?category .\n",
       "}\n",
       "GROUP BY ?category\n",
       "ORDER BY DESC(?managerCount)\n",
       "LIMIT 1\n",
       "```\n",
       "\n",
       "### Explanation of the Query:\n",
       "- **PREFIX Definitions**: We define the necessary prefixes for the vocabulary used in the query.\n",
       "- **SELECT Clause**: We select the `?category` and the count of `?manager` as `?managerCount`.\n",
       "- **WHERE Clause**: \n",
       "  - We specify that `?manager` must be of type `pv:Manager`.\n",
       "  - We link each manager to their area of expertise using the property `pv:areaOfExpertise`, which points to the `?category`.\n",
       "- **GROUP BY Clause**: This groups the results by `?category`, allowing us to count the number of managers per category.\n",
       "- **ORDER BY Clause**: We order the results by the count of managers in descending order to get the category with the most managers at the top.\n",
       "- **LIMIT Clause**: We limit the results to just one, which will be the category with the highest count of product managers.\n",
       "\n",
       "This refined query should effectively answer the user's question by providing the product category with the most product managers as experts.\n",
       "-----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### SPARQL list\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```sparql\n",
       "PREFIX pv: <http://ld.company.org/prod-vocab/>\n",
       "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
       "\n",
       "SELECT ?category (COUNT(?manager) AS ?managerCount)\n",
       "WHERE {\n",
       "    ?manager a pv:Manager .\n",
       "    ?manager pv:areaOfExpertise ?category .\n",
       "}\n",
       "GROUP BY ?category\n",
       "ORDER BY DESC(?managerCount)\n",
       "LIMIT 1\n",
       "-----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```sparql\n",
       "PREFIX pv: <http://ld.company.org/prod-vocab/>\n",
       "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
       "\n",
       "SELECT ?category (COUNT(?manager) AS ?managerCount)\n",
       "WHERE {\n",
       "    ?manager a pv:Manager .\n",
       "    ?manager pv:areaOfExpertise ?category .\n",
       "}\n",
       "GROUP BY ?category\n",
       "ORDER BY DESC(?managerCount)\n",
       "LIMIT 1\n",
       "-----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def refine(prompt: str) -> None:\n",
    "    \"\"\"Refine the sparql query.\"\"\"\n",
    "    display(Markdown(f\"## Prompt: _{prompt}_\"))\n",
    "    cmem_query_refined = cmem_query_builder.refine_sparql(\n",
    "        question=question, cmem_query=generated_cmem_query\n",
    "    )\n",
    "    display(Markdown(\"### Prediction list\\n\\n\"))\n",
    "    for prediction in cmem_query_refined.get_prediction_list():\n",
    "        display(Markdown(f\"{prediction!s}\\n-----\\n\"))\n",
    "    display(Markdown(\"### SPARQL list\\n\\n\"))\n",
    "    for sparql in cmem_query_refined.get_sparql_list():\n",
    "        display(Markdown(f\"```sparql\\n{sparql!s}\\n-----\\n\"))\n",
    "\n",
    "\n",
    "refine(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
